[{
  "history_id" : "nxd0vf9p7fr",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs and print loss values\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\n\n# Print the loss values after each epoch\ntrain_loss = history['loss']\nval_loss = history['val_loss']\n\nprint(\"Epoch-wise Losses:\")\nfor i in range(len(train_loss)):\n    print(f\"Epoch {i+1}: Train Loss = {train_loss[i]}, Validation Loss = {val_loss[i]}\")\n\n# Plot the loss curves\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Epoch-wise Losses:\nEpoch 1: Train Loss = 0.03072919137775898, Validation Loss = 0.01742088980972767\nEpoch 2: Train Loss = 0.011098137125372887, Validation Loss = 0.02268320694565773\nEpoch 3: Train Loss = 0.010209755040705204, Validation Loss = 0.01720193214714527\nEpoch 4: Train Loss = 0.00854005292057991, Validation Loss = 0.012641695328056812\nEpoch 5: Train Loss = 0.007384682539850473, Validation Loss = 0.017973309382796288\nEpoch 6: Train Loss = 0.006740374490618706, Validation Loss = 0.009798855520784855\nEpoch 7: Train Loss = 0.005943419877439737, Validation Loss = 0.010053860954940319\nEpoch 8: Train Loss = 0.00539526529610157, Validation Loss = 0.01057480089366436\nEpoch 9: Train Loss = 0.005453225690871477, Validation Loss = 0.00832605641335249\nEpoch 10: Train Loss = 0.005200219806283712, Validation Loss = 0.006214628461748362\nEpoch 11: Train Loss = 0.005218852777034044, Validation Loss = 0.006327028851956129\nEpoch 12: Train Loss = 0.005223800893872976, Validation Loss = 0.011008824221789837\nEpoch 13: Train Loss = 0.0046732318587601185, Validation Loss = 0.0043561640195548534\nEpoch 14: Train Loss = 0.004665676970034838, Validation Loss = 0.005817031487822533\nEpoch 15: Train Loss = 0.004796288441866636, Validation Loss = 0.009089156053960323\nEpoch 16: Train Loss = 0.004646167159080505, Validation Loss = 0.013137206435203552\nEpoch 17: Train Loss = 0.005103453528136015, Validation Loss = 0.003600385505706072\nEpoch 18: Train Loss = 0.0041281539015471935, Validation Loss = 0.005638223607093096\nEpoch 19: Train Loss = 0.004267961252480745, Validation Loss = 0.006245030555874109\nEpoch 20: Train Loss = 0.004086713772267103, Validation Loss = 0.0034914754796773195\n2024-09-27 16:54:53.436 python[37713:5819922] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-27 16:54:53.436 python[37713:5819922] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727470492208,
  "history_end_time" : 1727470496947,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "rXqbdDZYuN7M",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs and print loss values\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\n\n# Print the loss values after each epoch\ntrain_loss = history['loss']\nval_loss = history['val_loss']\n\nprint(\"Epoch-wise Losses:\")\nfor i in range(len(train_loss)):\n    print(f\"Epoch {i+1}: Train Loss = {train_loss[i]}, Validation Loss = {val_loss[i]}\")\n\n# Plot the loss curves\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Epoch-wise Losses:\nEpoch 1: Train Loss = 0.03072919137775898, Validation Loss = 0.01742088980972767\nEpoch 2: Train Loss = 0.011098137125372887, Validation Loss = 0.02268320694565773\nEpoch 3: Train Loss = 0.010209755040705204, Validation Loss = 0.01720193214714527\nEpoch 4: Train Loss = 0.00854005292057991, Validation Loss = 0.012641695328056812\nEpoch 5: Train Loss = 0.007384682539850473, Validation Loss = 0.017973309382796288\nEpoch 6: Train Loss = 0.006740374490618706, Validation Loss = 0.009798855520784855\nEpoch 7: Train Loss = 0.005943419877439737, Validation Loss = 0.010053860954940319\nEpoch 8: Train Loss = 0.00539526529610157, Validation Loss = 0.01057480089366436\nEpoch 9: Train Loss = 0.005453225690871477, Validation Loss = 0.00832605641335249\nEpoch 10: Train Loss = 0.005200219806283712, Validation Loss = 0.006214628461748362\nEpoch 11: Train Loss = 0.005218852777034044, Validation Loss = 0.006327028851956129\nEpoch 12: Train Loss = 0.005223800893872976, Validation Loss = 0.011008824221789837\nEpoch 13: Train Loss = 0.0046732318587601185, Validation Loss = 0.0043561640195548534\nEpoch 14: Train Loss = 0.004665676970034838, Validation Loss = 0.005817031487822533\nEpoch 15: Train Loss = 0.004796288441866636, Validation Loss = 0.009089156053960323\nEpoch 16: Train Loss = 0.004646167159080505, Validation Loss = 0.013137206435203552\nEpoch 17: Train Loss = 0.005103453528136015, Validation Loss = 0.003600385505706072\nEpoch 18: Train Loss = 0.0041281539015471935, Validation Loss = 0.005638223607093096\nEpoch 19: Train Loss = 0.004267961252480745, Validation Loss = 0.006245030555874109\nEpoch 20: Train Loss = 0.004086713772267103, Validation Loss = 0.0034914754796773195\n2024-09-27 16:53:15.747 python[37625:5810644] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-27 16:53:15.747 python[37625:5810644] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727470394573,
  "history_end_time" : 1727470399889,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "4xt00ltpryt",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs and print loss values\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\n\n# Print the loss values after each epoch\ntrain_loss = history['loss']\nval_loss = history['val_loss']\n\nprint(\"Epoch-wise Losses:\")\nfor i in range(len(train_loss)):\n    print(f\"Epoch {i+1}: Train Loss = {train_loss[i]}, Validation Loss = {val_loss[i]}\")\n\n# Plot the loss curves\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Epoch-wise Losses:\nEpoch 1: Train Loss = 0.03072919137775898, Validation Loss = 0.01742088980972767\nEpoch 2: Train Loss = 0.011098137125372887, Validation Loss = 0.02268320694565773\nEpoch 3: Train Loss = 0.010209755040705204, Validation Loss = 0.01720193214714527\nEpoch 4: Train Loss = 0.00854005292057991, Validation Loss = 0.012641695328056812\nEpoch 5: Train Loss = 0.007384682539850473, Validation Loss = 0.017973309382796288\nEpoch 6: Train Loss = 0.006740374490618706, Validation Loss = 0.009798855520784855\nEpoch 7: Train Loss = 0.005943419877439737, Validation Loss = 0.010053860954940319\nEpoch 8: Train Loss = 0.00539526529610157, Validation Loss = 0.01057480089366436\nEpoch 9: Train Loss = 0.005453225690871477, Validation Loss = 0.00832605641335249\nEpoch 10: Train Loss = 0.005200219806283712, Validation Loss = 0.006214628461748362\nEpoch 11: Train Loss = 0.005218852777034044, Validation Loss = 0.006327028851956129\nEpoch 12: Train Loss = 0.005223800893872976, Validation Loss = 0.011008824221789837\nEpoch 13: Train Loss = 0.0046732318587601185, Validation Loss = 0.0043561640195548534\nEpoch 14: Train Loss = 0.004665676970034838, Validation Loss = 0.005817031487822533\nEpoch 15: Train Loss = 0.004796288441866636, Validation Loss = 0.009089156053960323\nEpoch 16: Train Loss = 0.004646167159080505, Validation Loss = 0.013137206435203552\nEpoch 17: Train Loss = 0.005103453528136015, Validation Loss = 0.003600385505706072\nEpoch 18: Train Loss = 0.0041281539015471935, Validation Loss = 0.005638223607093096\nEpoch 19: Train Loss = 0.004267961252480745, Validation Loss = 0.006245030555874109\nEpoch 20: Train Loss = 0.004086713772267103, Validation Loss = 0.0034914754796773195\n2024-09-27 16:18:34.506 python[35583:5739476] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-27 16:18:34.506 python[35583:5739476] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727468313199,
  "history_end_time" : 1727468320743,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Done"
},{
  "history_id" : "znt4AT4EenSi",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs and print loss values\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\n\n# Print the loss values after each epoch\ntrain_loss = history['loss']\nval_loss = history['val_loss']\n\nprint(\"Epoch-wise Losses:\")\nfor i in range(len(train_loss)):\n    print(f\"Epoch {i+1}: Train Loss = {train_loss[i]}, Validation Loss = {val_loss[i]}\")\n\n# Plot the loss curves\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Epoch-wise Losses:\nEpoch 1: Train Loss = 0.03072919137775898, Validation Loss = 0.01742088980972767\nEpoch 2: Train Loss = 0.011098137125372887, Validation Loss = 0.02268320694565773\nEpoch 3: Train Loss = 0.010209755040705204, Validation Loss = 0.01720193214714527\nEpoch 4: Train Loss = 0.00854005292057991, Validation Loss = 0.012641695328056812\nEpoch 5: Train Loss = 0.007384682539850473, Validation Loss = 0.017973309382796288\nEpoch 6: Train Loss = 0.006740374490618706, Validation Loss = 0.009798855520784855\nEpoch 7: Train Loss = 0.005943419877439737, Validation Loss = 0.010053860954940319\nEpoch 8: Train Loss = 0.00539526529610157, Validation Loss = 0.01057480089366436\nEpoch 9: Train Loss = 0.005453225690871477, Validation Loss = 0.00832605641335249\nEpoch 10: Train Loss = 0.005200219806283712, Validation Loss = 0.006214628461748362\nEpoch 11: Train Loss = 0.005218852777034044, Validation Loss = 0.006327028851956129\nEpoch 12: Train Loss = 0.005223800893872976, Validation Loss = 0.011008824221789837\nEpoch 13: Train Loss = 0.0046732318587601185, Validation Loss = 0.0043561640195548534\nEpoch 14: Train Loss = 0.004665676970034838, Validation Loss = 0.005817031487822533\nEpoch 15: Train Loss = 0.004796288441866636, Validation Loss = 0.009089156053960323\nEpoch 16: Train Loss = 0.004646167159080505, Validation Loss = 0.013137206435203552\nEpoch 17: Train Loss = 0.005103453528136015, Validation Loss = 0.003600385505706072\nEpoch 18: Train Loss = 0.0041281539015471935, Validation Loss = 0.005638223607093096\nEpoch 19: Train Loss = 0.004267961252480745, Validation Loss = 0.006245030555874109\nEpoch 20: Train Loss = 0.004086713772267103, Validation Loss = 0.0034914754796773195\n2024-09-27 16:13:42.184 python[35325:5723578] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-27 16:13:42.184 python[35325:5723578] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727468020996,
  "history_end_time" : 1727468030079,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "85LpYKN22Zc7",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs and print loss values\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\n\n# Print the loss values after each epoch\ntrain_loss = history['loss']\nval_loss = history['val_loss']\n\nprint(\"Epoch-wise Losses:\")\nfor i in range(len(train_loss)):\n    print(f\"Epoch {i+1}: Train Loss = {train_loss[i]}, Validation Loss = {val_loss[i]}\")\n\n# Plot the loss curves\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Epoch-wise Losses:\nEpoch 1: Train Loss = 0.03072919137775898, Validation Loss = 0.01742088980972767\nEpoch 2: Train Loss = 0.011098137125372887, Validation Loss = 0.02268320694565773\nEpoch 3: Train Loss = 0.010209755040705204, Validation Loss = 0.01720193214714527\nEpoch 4: Train Loss = 0.00854005292057991, Validation Loss = 0.012641695328056812\nEpoch 5: Train Loss = 0.007384682539850473, Validation Loss = 0.017973309382796288\nEpoch 6: Train Loss = 0.006740374490618706, Validation Loss = 0.009798855520784855\nEpoch 7: Train Loss = 0.005943419877439737, Validation Loss = 0.010053860954940319\nEpoch 8: Train Loss = 0.00539526529610157, Validation Loss = 0.01057480089366436\nEpoch 9: Train Loss = 0.005453225690871477, Validation Loss = 0.00832605641335249\nEpoch 10: Train Loss = 0.005200219806283712, Validation Loss = 0.006214628461748362\nEpoch 11: Train Loss = 0.005218852777034044, Validation Loss = 0.006327028851956129\nEpoch 12: Train Loss = 0.005223800893872976, Validation Loss = 0.011008824221789837\nEpoch 13: Train Loss = 0.0046732318587601185, Validation Loss = 0.0043561640195548534\nEpoch 14: Train Loss = 0.004665676970034838, Validation Loss = 0.005817031487822533\nEpoch 15: Train Loss = 0.004796288441866636, Validation Loss = 0.009089156053960323\nEpoch 16: Train Loss = 0.004646167159080505, Validation Loss = 0.013137206435203552\nEpoch 17: Train Loss = 0.005103453528136015, Validation Loss = 0.003600385505706072\nEpoch 18: Train Loss = 0.0041281539015471935, Validation Loss = 0.005638223607093096\nEpoch 19: Train Loss = 0.004267961252480745, Validation Loss = 0.006245030555874109\nEpoch 20: Train Loss = 0.004086713772267103, Validation Loss = 0.0034914754796773195\n2024-09-27 16:09:41.276 python[35122:5717143] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-27 16:09:41.276 python[35122:5717143] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727467779713,
  "history_end_time" : 1727467786568,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "TM2pDSO1j3dS",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs and print loss values\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\n\n# Print the loss values after each epoch\ntrain_loss = history['loss']\nval_loss = history['val_loss']\n\nprint(\"Epoch-wise Losses:\")\nfor i in range(len(train_loss)):\n    print(f\"Epoch {i+1}: Train Loss = {train_loss[i]}, Validation Loss = {val_loss[i]}\")\n\n# Plot the loss curves\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Epoch-wise Losses:\nEpoch 1: Train Loss = 0.03072919137775898, Validation Loss = 0.01742088980972767\nEpoch 2: Train Loss = 0.011098137125372887, Validation Loss = 0.02268320694565773\nEpoch 3: Train Loss = 0.010209755040705204, Validation Loss = 0.01720193214714527\nEpoch 4: Train Loss = 0.00854005292057991, Validation Loss = 0.012641695328056812\nEpoch 5: Train Loss = 0.007384682539850473, Validation Loss = 0.017973309382796288\nEpoch 6: Train Loss = 0.006740374490618706, Validation Loss = 0.009798855520784855\nEpoch 7: Train Loss = 0.005943419877439737, Validation Loss = 0.010053860954940319\nEpoch 8: Train Loss = 0.00539526529610157, Validation Loss = 0.01057480089366436\nEpoch 9: Train Loss = 0.005453225690871477, Validation Loss = 0.00832605641335249\nEpoch 10: Train Loss = 0.005200219806283712, Validation Loss = 0.006214628461748362\nEpoch 11: Train Loss = 0.005218852777034044, Validation Loss = 0.006327028851956129\nEpoch 12: Train Loss = 0.005223800893872976, Validation Loss = 0.011008824221789837\nEpoch 13: Train Loss = 0.0046732318587601185, Validation Loss = 0.0043561640195548534\nEpoch 14: Train Loss = 0.004665676970034838, Validation Loss = 0.005817031487822533\nEpoch 15: Train Loss = 0.004796288441866636, Validation Loss = 0.009089156053960323\nEpoch 16: Train Loss = 0.004646167159080505, Validation Loss = 0.013137206435203552\nEpoch 17: Train Loss = 0.005103453528136015, Validation Loss = 0.003600385505706072\nEpoch 18: Train Loss = 0.0041281539015471935, Validation Loss = 0.005638223607093096\nEpoch 19: Train Loss = 0.004267961252480745, Validation Loss = 0.006245030555874109\nEpoch 20: Train Loss = 0.004086713772267103, Validation Loss = 0.0034914754796773195\n2024-09-25 14:47:20.944 python[94308:4248017] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-25 14:47:20.944 python[94308:4248017] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727290039336,
  "history_end_time" : 1727290050847,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "7XywNGHyScGN",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs and print loss values\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\n\n# Print the loss values after each epoch\ntrain_loss = history['loss']\nval_loss = history['val_loss']\n\nprint(\"Epoch-wise Losses:\")\nfor i in range(len(train_loss)):\n    print(f\"Epoch {i+1}: Train Loss = {train_loss[i]}, Validation Loss = {val_loss[i]}\")\n\n# Plot the loss curves\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Epoch-wise Losses:\nEpoch 1: Train Loss = 0.03072919137775898, Validation Loss = 0.01742088980972767\nEpoch 2: Train Loss = 0.011098137125372887, Validation Loss = 0.02268320694565773\nEpoch 3: Train Loss = 0.010209755040705204, Validation Loss = 0.01720193214714527\nEpoch 4: Train Loss = 0.00854005292057991, Validation Loss = 0.012641695328056812\nEpoch 5: Train Loss = 0.007384682539850473, Validation Loss = 0.017973309382796288\nEpoch 6: Train Loss = 0.006740374490618706, Validation Loss = 0.009798855520784855\nEpoch 7: Train Loss = 0.005943419877439737, Validation Loss = 0.010053860954940319\nEpoch 8: Train Loss = 0.00539526529610157, Validation Loss = 0.01057480089366436\nEpoch 9: Train Loss = 0.005453225690871477, Validation Loss = 0.00832605641335249\nEpoch 10: Train Loss = 0.005200219806283712, Validation Loss = 0.006214628461748362\nEpoch 11: Train Loss = 0.005218852777034044, Validation Loss = 0.006327028851956129\nEpoch 12: Train Loss = 0.005223800893872976, Validation Loss = 0.011008824221789837\nEpoch 13: Train Loss = 0.0046732318587601185, Validation Loss = 0.0043561640195548534\nEpoch 14: Train Loss = 0.004665676970034838, Validation Loss = 0.005817031487822533\nEpoch 15: Train Loss = 0.004796288441866636, Validation Loss = 0.009089156053960323\nEpoch 16: Train Loss = 0.004646167159080505, Validation Loss = 0.013137206435203552\nEpoch 17: Train Loss = 0.005103453528136015, Validation Loss = 0.003600385505706072\nEpoch 18: Train Loss = 0.0041281539015471935, Validation Loss = 0.005638223607093096\nEpoch 19: Train Loss = 0.004267961252480745, Validation Loss = 0.006245030555874109\nEpoch 20: Train Loss = 0.004086713772267103, Validation Loss = 0.0034914754796773195\n2024-09-25 14:43:30.424 python[94163:4241146] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-25 14:43:30.424 python[94163:4241146] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727289808939,
  "history_end_time" : 1727289820324,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "4VCYFmS87aFY",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs and print loss values\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\n\n# Print the loss values after each epoch\ntrain_loss = history['loss']\nval_loss = history['val_loss']\n\nprint(\"Epoch-wise Losses:\")\nfor i in range(len(train_loss)):\n    print(f\"Epoch {i+1}: Train Loss = {train_loss[i]}, Validation Loss = {val_loss[i]}\")\n\n# Plot the loss curves\nplt.plot(train_loss, label='Train Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Epoch-wise Losses:\nEpoch 1: Train Loss = 0.03072919137775898, Validation Loss = 0.01742088980972767\nEpoch 2: Train Loss = 0.011098137125372887, Validation Loss = 0.02268320694565773\nEpoch 3: Train Loss = 0.010209755040705204, Validation Loss = 0.01720193214714527\nEpoch 4: Train Loss = 0.00854005292057991, Validation Loss = 0.012641695328056812\nEpoch 5: Train Loss = 0.007384682539850473, Validation Loss = 0.017973309382796288\nEpoch 6: Train Loss = 0.006740374490618706, Validation Loss = 0.009798855520784855\nEpoch 7: Train Loss = 0.005943419877439737, Validation Loss = 0.010053860954940319\nEpoch 8: Train Loss = 0.00539526529610157, Validation Loss = 0.01057480089366436\nEpoch 9: Train Loss = 0.005453225690871477, Validation Loss = 0.00832605641335249\nEpoch 10: Train Loss = 0.005200219806283712, Validation Loss = 0.006214628461748362\nEpoch 11: Train Loss = 0.005218852777034044, Validation Loss = 0.006327028851956129\nEpoch 12: Train Loss = 0.005223800893872976, Validation Loss = 0.011008824221789837\nEpoch 13: Train Loss = 0.0046732318587601185, Validation Loss = 0.0043561640195548534\nEpoch 14: Train Loss = 0.004665676970034838, Validation Loss = 0.005817031487822533\nEpoch 15: Train Loss = 0.004796288441866636, Validation Loss = 0.009089156053960323\nEpoch 16: Train Loss = 0.004646167159080505, Validation Loss = 0.013137206435203552\nEpoch 17: Train Loss = 0.005103453528136015, Validation Loss = 0.003600385505706072\nEpoch 18: Train Loss = 0.0041281539015471935, Validation Loss = 0.005638223607093096\nEpoch 19: Train Loss = 0.004267961252480745, Validation Loss = 0.006245030555874109\nEpoch 20: Train Loss = 0.004086713772267103, Validation Loss = 0.0034914754796773195\n2024-09-25 14:39:37.853 python[93807:4230626] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-25 14:39:37.853 python[93807:4230626] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727289576063,
  "history_end_time" : 1727289652185,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "RcZAJNi8q3P7",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\nplt.plot(history['loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "2024-09-25 14:31:56.435 python[93499:4217187] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-25 14:31:56.435 python[93499:4217187] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727289115196,
  "history_end_time" : 1727289135850,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "b1q2rl2qwXSp",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\nplt.plot(history['loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "2024-09-25 14:31:19.552 python[93465:4215521] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-25 14:31:19.552 python[93465:4215521] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727289078027,
  "history_end_time" : 1727289112581,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "G8XHeAnYae0R",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/f7bNu3SQ6blN/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\nplt.plot(history['loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "2024-09-25 13:22:12.439 python[90244:4130705] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-25 13:22:12.439 python[90244:4130705] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727284930852,
  "history_end_time" : 1727285256083,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "I3AZVG7Vwnnj",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\nplt.plot(history['loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/vishesh/gw-workspace/I3AZVG7Vwnnj/visualization.py\", line 55, in <module>\n    scaler = joblib.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/scaler.pkl')\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\n         ^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/vishesh/gw-workspace/L6gDfkNJofh8/scaler.pkl'\n",
  "history_begin_time" : 1727284808839,
  "history_end_time" : 1727284809489,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "46jo30C2VsOz",
  "history_input" : "# import pandas as pd\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n\n# def visualize(file_name, predictions_file, anomalies_file):\n#     data = pd.read_csv(file_name)\n#     predictions = pd.read_csv(predictions_file)\n#     anomalies = pd.read_csv(anomalies_file)\n    \n#     plt.figure(figsize=(12, 8))\n    \n#     # Plotting temperature trends with predictions\n#     plt.subplot(2, 1, 1)\n#     plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n#     plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n#     plt.title('Temperature Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Temperature (°C)')\n#     plt.legend()\n    \n#     # Plotting precipitation trends with predictions\n#     plt.subplot(2, 1, 2)\n#     plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n#     plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n#     plt.title('Precipitation Trends and Predictions')\n#     plt.xlabel('Year')\n#     plt.ylabel('Precipitation (mm)')\n#     plt.legend()\n    \n#     # Highlighting anomalies\n#     sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n#     plt.tight_layout()\n#     plt.savefig('climate_trends_and_anomalies.png')\n#     plt.show()\n\n# if __name__ == \"__main__\":\n#     visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n\n\n\n\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport joblib\n\n# Step 1: Load predictions, actual values, and scaler\npredictions = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/predictions.npy')\ndata = np.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/preprocessed_data.npz')\ny_test = data['y_test']\n\n# Load the scaler for inverse transformation\nscaler = joblib.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/scaler.pkl')\n\n# Step 2: Inverse scale the predictions and real values\npredicted_values = scaler.inverse_transform(predictions)\nreal_values = scaler.inverse_transform(y_test.reshape(-1, 1))\n\n# Step 3: Visualize the loss over epochs\nhistory = np.load('/Users/vishesh/gw-workspace/9I3eI9y6wb9B/training_history.npy', allow_pickle=True).item()\nplt.plot(history['loss'], label='Train Loss')\nplt.plot(history['val_loss'], label='Validation Loss')\nplt.title('Model Loss over Epochs')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n\n# Step 4: Visualize the predicted vs actual values\nplt.plot(real_values, color='blue', label='Real Temperature Values')\nplt.plot(predicted_values, color='red', label='Predicted Temperature Values')\nplt.title('Real vs Predicted Temperature Values')\nplt.xlabel('Time')\nplt.ylabel('Temperature')\nplt.legend()\nplt.show()\n",
  "history_output" : "Traceback (most recent call last):\n  File \"/Users/vishesh/gw-workspace/46jo30C2VsOz/visualization.py\", line 55, in <module>\n    scaler = joblib.load('/Users/vishesh/gw-workspace/L6gDfkNJofh8/scaler.pkl')\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/anaconda3/lib/python3.11/site-packages/joblib/numpy_pickle.py\", line 650, in load\n    with open(filename, 'rb') as f:\n         ^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/vishesh/gw-workspace/L6gDfkNJofh8/scaler.pkl'\n",
  "history_begin_time" : 1727205947446,
  "history_end_time" : 1727205948171,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Failed"
},{
  "history_id" : "lX0CMTIKGXoA",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef visualize(file_name, predictions_file, anomalies_file):\n    data = pd.read_csv(file_name)\n    predictions = pd.read_csv(predictions_file)\n    anomalies = pd.read_csv(anomalies_file)\n    \n    plt.figure(figsize=(12, 8))\n    \n    # Plotting temperature trends with predictions\n    plt.subplot(2, 1, 1)\n    plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n    plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n    plt.title('Temperature Trends and Predictions')\n    plt.xlabel('Year')\n    plt.ylabel('Temperature (°C)')\n    plt.legend()\n    \n    # Plotting precipitation trends with predictions\n    plt.subplot(2, 1, 2)\n    plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n    plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n    plt.title('Precipitation Trends and Predictions')\n    plt.xlabel('Year')\n    plt.ylabel('Precipitation (mm)')\n    plt.legend()\n    \n    # Highlighting anomalies\n    sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n    plt.tight_layout()\n    plt.savefig('climate_trends_and_anomalies.png')\n    plt.show()\n\nif __name__ == \"__main__\":\n    visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n",
  "history_output" : "2024-09-24 14:36:17.405 python[80035:3738028] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-24 14:36:17.405 python[80035:3738028] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727202975418,
  "history_end_time" : 1727202993426,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "oUUikmIpDf6i",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef visualize(file_name, predictions_file, anomalies_file):\n    data = pd.read_csv(file_name)\n    predictions = pd.read_csv(predictions_file)\n    anomalies = pd.read_csv(anomalies_file)\n    \n    plt.figure(figsize=(12, 8))\n    \n    # Plotting temperature trends with predictions\n    plt.subplot(2, 1, 1)\n    plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n    plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n    plt.title('Temperature Trends and Predictions')\n    plt.xlabel('Year')\n    plt.ylabel('Temperature (°C)')\n    plt.legend()\n    \n    # Plotting precipitation trends with predictions\n    plt.subplot(2, 1, 2)\n    plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n    plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n    plt.title('Precipitation Trends and Predictions')\n    plt.xlabel('Year')\n    plt.ylabel('Precipitation (mm)')\n    plt.legend()\n    \n    # Highlighting anomalies\n    sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n    plt.tight_layout()\n    plt.savefig('climate_trends_and_anomalies.png')\n    plt.show()\n\nif __name__ == \"__main__\":\n    visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n",
  "history_output" : "2024-09-24 14:33:47.623 python[79946:3733869] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-24 14:33:47.623 python[79946:3733869] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727202825668,
  "history_end_time" : 1727202835393,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "B0Vwp6Ytx3oJ",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef visualize(file_name, predictions_file, anomalies_file):\n    data = pd.read_csv(file_name)\n    predictions = pd.read_csv(predictions_file)\n    anomalies = pd.read_csv(anomalies_file)\n    \n    plt.figure(figsize=(12, 8))\n    \n    # Plotting temperature trends with predictions\n    plt.subplot(2, 1, 1)\n    plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n    plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n    plt.title('Temperature Trends and Predictions')\n    plt.xlabel('Year')\n    plt.ylabel('Temperature (°C)')\n    plt.legend()\n    \n    # Plotting precipitation trends with predictions\n    plt.subplot(2, 1, 2)\n    plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n    plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n    plt.title('Precipitation Trends and Predictions')\n    plt.xlabel('Year')\n    plt.ylabel('Precipitation (mm)')\n    plt.legend()\n    \n    # Highlighting anomalies\n    sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n    plt.tight_layout()\n    plt.savefig('climate_trends_and_anomalies.png')\n    plt.show()\n\nif __name__ == \"__main__\":\n    visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n",
  "history_output" : "2024-09-24 14:28:21.507 python[79723:3725723] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-24 14:28:21.507 python[79723:3725723] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727202499440,
  "history_end_time" : 1727202585011,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "gY2ZQMj2s08T",
  "history_input" : "import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef visualize(file_name, predictions_file, anomalies_file):\n    data = pd.read_csv(file_name)\n    predictions = pd.read_csv(predictions_file)\n    anomalies = pd.read_csv(anomalies_file)\n    \n    plt.figure(figsize=(12, 8))\n    \n    # Plotting temperature trends with predictions\n    plt.subplot(2, 1, 1)\n    plt.plot(data['Year'], data['Temp_Value'], label='Observed Temperature')\n    plt.plot(predictions['Year'], predictions['Temp_Prediction'], label='Predicted Temperature', linestyle='--')\n    plt.title('Temperature Trends and Predictions')\n    plt.xlabel('Year')\n    plt.ylabel('Temperature (°C)')\n    plt.legend()\n    \n    # Plotting precipitation trends with predictions\n    plt.subplot(2, 1, 2)\n    plt.plot(data['Year'], data['Precipitation'], label='Observed Precipitation')\n    plt.plot(predictions['Year'], predictions['Precip_Prediction'], label='Predicted Precipitation', linestyle='--')\n    plt.title('Precipitation Trends and Predictions')\n    plt.xlabel('Year')\n    plt.ylabel('Precipitation (mm)')\n    plt.legend()\n    \n    # Highlighting anomalies\n    sns.scatterplot(data=anomalies, x='Year', y='Temp_Value', hue='Cluster', palette='deep', legend='full', s=100)\n    \n    plt.tight_layout()\n    plt.savefig('climate_trends_and_anomalies.png')\n    plt.show()\n\nif __name__ == \"__main__\":\n    visualize('/Users/vishesh/Desktop/geo_project/analyzed_climate_data.csv', '/Users/vishesh/Desktop/geo_project/predicted_climate_data.csv', '/Users/vishesh/Desktop/geo_project/anomaly_detected_data.csv')\n",
  "history_output" : "2024-09-24 14:23:29.483 python[79487:3717431] +[IMKClient subclass]: chose IMKClient_Legacy\n2024-09-24 14:23:29.483 python[79487:3717431] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n",
  "history_begin_time" : 1727202206027,
  "history_end_time" : 1727202360723,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : null,
  "indicator" : "Done"
},{
  "history_id" : "x2q0yts3uxz",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1727468247465,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "8s32ng2oedu",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1727468349712,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "amd4fb52375",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1727468384413,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "ljqgrgnfz1u",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1727468509406,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "13z8kfv2j4c",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1727468627587,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "1v3rqrb8760",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1727468668269,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Stopped"
},{
  "history_id" : "x36cocy6xkp",
  "history_input" : null,
  "history_output" : null,
  "history_begin_time" : null,
  "history_end_time" : 1727468706486,
  "history_notes" : null,
  "history_process" : "x4ch0z",
  "host_id" : "100001",
  "indicator" : "Stopped"
},]
